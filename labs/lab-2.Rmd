---
title: "Lab 2: R Basics and Descriptives"
output: 
  html_document: 
    theme: cosmo
    toc: yes
    toc_depth: 3
    toc_float: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# suppress scientific notation
options(scipen = 999)

# load libraries
library(tidyverse)
library(here)
library(rio)
library(psych)
```


# Purpose

The purpose of today's lab is to introduce you to some simple tools that will allow you to calculate and visualize **descriptive statistics** in R. This will not be a deep dive into the theoretical meaning behind descriptives, but rather a guide to some practical steps toward getting the most basic summary information out of a given dataset. Along the way, we will implement some of the skills we learned in [last week's lab](https://uopsych.github.io/psy611/labs/lab-1.html){target="_blank"}, such as creating variables, working with data frames, installing packages, and learning how to use new functions. 

Today's lab will cover:

1. [Visualizing Distributions](#dist)
2. [Basic Descriptives](#basic)
3. [Summarizing a dataset](#summarize)
4. [Bivariate Descriptives](#bivar)

***

# Getting Started

We'll use the same 2015 World Happiness Report dataset from class, which you can [download here](https://drive.google.com/uc?export=download&id=1XXsB4L4wDxGkcc-JuVnotKWCnsDUsskW). Go ahead and import the data using the `rio` package (see [here](https://uopsych.github.io/psy611/labs/lab-1.html#importing_data_into_r){target="_blank"} for a refresher on importing data.)

If the file is saved in your `Downloads` folder, your code might look something like this:
```{r, eval = FALSE}
library(rio) # use install.packages("rio") if the 'rio' package is not already installed
world_happiness <- import("~/Downloads/world_happiness_2015.csv")
```


```{r, echo=FALSE}
world_happiness = import(here("/labs/resources/lab2/purpose/world_happiness_2015.csv"))
```

We can take a peek at the data using the `str()` function, which shows us the structure of the dataset. This tells us we have a data frame with 136 observations of 8 different variables: `Country`, `Happiness`, `GDP`, `Support`, `Life`, `Freedom`, `Generosity` and `Corruption`. 

```{r}
str(world_happiness)
```

We can also peek at the first few rows of the data frame using `head()`.

```{r}
head(world_happiness)
```

***

# Visualizing Distributions {#dist}

Recall from lecture that a **distribution** often refers to a description of the (relative) number of times a given variable will take each of its unique values.

## Histogram

One common way of visualizing distributions is using a **histogram**, which plots the frequencies of different values for a given variable.

For example, let's take a look at a distribution of the `Happiness` variable. We do this using the `hist()` function. (Remember, you can check out the help documentation using `?hist`).

```{r}
hist(x = world_happiness$Happiness)
```

This looks ok, but it's kind of ugly. Let's make it better by adding our own title and a better label for the x-axis. We can also change the number of bars using the `breaks` argument. 

```{r}
hist(x = world_happiness$Happiness, breaks = 30, main = "Histogram of Happiness Scores", xlab = "Happiness")
```

## Box Plot

We can also visualize distributions using a **boxplot**, which gives us different information. For a short guide on how to read boxplots, see [here](https://flowingdata.com/2008/02/15/how-to-read-and-use-a-box-and-whisker-plot/){target="_blank"} or refer to [this section](https://learningstatisticswithr-bookdown.netlify.com/graphics.html#boxplots){target="_blank"} of your textbook.

```{r}
boxplot(x = world_happiness$Happiness, main = "Boxplot of Happiness Scores")
```

## Looking ahead...

So far we have been plotting in base R. However, the [ggplot2 package](https://www.rdocumentation.org/packages/ggplot2/versions/3.2.1){target="_blank"} is generally a much better tool for plotting. For now we'll stick with base plotting to keep things simple, but in a future class you will learn how to use `ggplot` to make better-looking plots, such as this:

```{r echo = FALSE}
ggplot(world_happiness, aes(x = Happiness)) +
  geom_histogram(fill = "#56B4E9",
                 color = "white",
                 alpha = 0.7,
                 bins = 30) + 
  labs(x = "Happiness",
       y = "Frequency",
       title = "Histogram of Happiness Scores",
       caption = "Source: 2015 World Happiness Report") +
  theme_minimal(base_size = 13)
```


Ok, so now that we know how to vizualize a basic distribution, let's think about how we commonly *characterize* distributions with descriptive statistics...

***

# Basic Descriptives {#basic}

This section will describe how to calculate some of the most commonly used descriptive statistics using simple functions in R.

## Measures of Central Tendency

For a given set of observations, measures of central tendency allow us to get the "gist" of the data--e.g. they tell us about where the "average" or the "mid-point" of the data lies. Let's take a really simple example first. We'll use a vector of integers as our dataset. 

```{r}
simple_vector <- c(1, 1, 1, 2, 2, 2, 2, 2, 3, 5, 5, 6, 7)
```

### Mean

The mean is the arithmetic average of a set of values. It represents the sum of those values divided by the total number of values. Let's do this using our simple example dataset.

```{r}
sum(simple_vector)/length(simple_vector)
```

However, a faster (and better) way to find the mean is to use the aptly named `mean()` function from base R.

```{r}
mean(simple_vector)
```

What happens if we try to calculate the mean when there are missing values in our data? Let's see what happens when we add a couple `NA`'s to our simple vector and calculate the mean.

```{r}
# add NA's
simple_vector_missing <- c(1, 1, NA, 1, 2, 2, 2, 2, 2, 3, 5, NA, 5, 6, 7)

mean(simple_vector_missing)
```

...It gives us an `NA`! The reason for this is that the mean is calulated by using every value for a given variable, so if you don't remove (or impute) the missing values before getting the mean, it won't work. If there are missing values in your data (which there often are in real life), then you will have to add an additional argument: `na.rm = TRUE`.

```{r}
mean(simple_vector_missing, na.rm = TRUE)
```


### Median

The median is the middle value of a set of observations: 50% of the data points fall below the median, and 50% fall above. To find the median, we can use the `median()` function from the `{stats}` package.

```{r}
median(simple_vector)
```

### Mode

Oddly enough, the core packages in R do not contain a function to find the mode. In the case of our very simple dataset, it is easy to determine that the mode (i.e. the most common value) is `2`. Your first [minihack exercise](#minihacks) will be to find the mode using the R package that accompanies your textbook.

## Measures of Variability

### Range

The range gives us the distance between the smallest and largest value in a dataset. You can find the range using the `range()` function, which will output the minimum and maximum values. 

```{r}
range(simple_vector)
```


### Variance and standard deviation

To find the variance and standard deviation, we use `var()` and `sd()`, respectively.

```{r}
# variance
var(simple_vector)

# standard deviation
sd(simple_vector)
```

***Note: As it pertains to missing data, the same rule described above for the `mean()` function also applies to these functions (namely, that you need to add the argument `na.rm = TRUE`.)

## Outliers

Outliers are extreme values in the data. They don't follow the same general pattern as all the other data. One easy way to detect outliers is to visually inspect a distribution for values that stand out. For example, if we add an extreme value to our simple vector, it is easy to see that it is an outlier when we look at the boxplot.

```{r}
# add extreme value (25)
simple_vector_outlier <- c(1, 1, 1, 2, 2, 2, 2, 2, 3, 5, 5, 6, 7, 25)

# visualize outlier with boxplot 
boxplot(simple_vector_outlier)
```
 
### z-scores

Another way to identify outliers is to **standardize** the scores in our dataset, i.e. to convert them to z-scores. To do this, we take each score's distance from the mean and divide it by the standard deviation: 

$$ z = \frac{x_i - M}{s} $$

This tells us, for each score, how many standard deviations it is away from the mean. Some people use the rule of thumb that if a score is above or below 3 standard deviations from the mean, it should be considered an outlier. 

To standardize scores in our dataset, we can use the `scale()` function. 

```{r}
simple_vector_outlier <- c(1, 1, 1, 2, 2, 2, 2, 2, 3, 5, 5, 6, 7, 25)

scale(simple_vector_outlier) %>% as.numeric() # the as.numeric() here just returns a vector instead of a matrix for formatting purposes
```

Based on this output, how many standard deviations above the mean is our extreme value, `25`? Should it be considered an outlier?

*** 

# Summarizing data {#summarize}

So far we have been calculating various descriptive statistics (somewhat painstakingly) using an assortment of different functions. So what if we have a dataset with a bunch of varaibles we want descriptive statistics for? Surely we don't want to calculate descriptives for each variable by hand...

Fortunately for us, there is a function called `describe()` from the `{psych}` package, which we can use to quickly summarize a whole set of variables in a dataset. Let's look back for a minute at our `world_happiness` dataset. 

## `psych::describe()`

This function automatically calculates all of the descriptives we reviewed above (and more!) 

```{r warning=FALSE}
# because "Country" is not a numeric variable, we'll remove it for now 
world_happiness_num <- world_happiness %>% 
  select(-Country) # don't worry about what this code means for now

psych::describe(world_happiness_num)
```

If we want to focus on a particular variable, we can calculate descriptives for that variable only.

```{r}
psych::describe(world_happiness$Happiness)
```

***Note that `psych::describe()` also gives us skew and kurtosis. 

***

# Bivariate Descriptives {#bivar}

Bivariate descriptives pertain to the relationship between two variables. 

## Correlation

### `cor()` function

To find the strength of the association between two varaibles we can use the `cor()` function from the `{psych}` package. For example, in our `world_happiness` dataset, we might want to know the strength of the relationship between a country's `Happiness` and average level of social support, i.e. `Support`. 

```{r}
cor(world_happiness$Happiness, world_happiness$Support, use = "pairwise.complete.obs")
```

Not surprisingly, we see that there is a strong positive association between happiness and social support.

***Note the use of `use = "pairwise.complete.obs"`. Because there is missing data in these variables, we can use this argument to tell R to only use observations in which there is no missing data for either variable.

### Scatterplots

If we want to see this relationship graphically, we can create a *scatterplot*. 

```{r}
plot(world_happiness$Support, world_happiness$Happiness, xlab = "Social Support", ylab = "Happiness", main = "Relationship between social support and happiness \nat the country level")
```

### `pairs.panels()` function

If we have a dataset with a reasonably small number of variables, we can use `pairs.panels()` (also from the `{psych}` package) to generate a matrix that contains scatterplots between all of the variables below the diagonal and Pearson correlations between all of the variables above the diagonal. 

```{r}
# use world_happiness_num since we only want correlations between numeric variables
pairs.panels(world_happiness_num)
```


## Covariance

Lastly, if we want to find the covariance between two variables, we use the `cov()` function.

```{r}
cov(world_happiness$Happiness, world_happiness$Support, use = "pairwise.complete.obs")
```

***

# Minihacks {#minihacks}

## Minihack 1: Find the mode

1. Install and load the `{lsr}` package, the companion R package to your textbook, [Learning Statistics with R](https://learningstatisticswithr-bookdown.netlify.com/){target="_blank"}.

2. Check out the help documentation for the function `modeOf()`. 

3. Use `modeOf()` to find the mode of `simple_vector`. Make sure that the answer you get is `2`. Save your result to an object called `mode`. If you don't already have `simple_vector` loaded in your workspace, here it is again:

```{r eval=FALSE}
simple_vector <- c(1, 1, 1, 2, 2, 2, 2, 2, 3, 5, 5, 6, 7)
```

4. Use the function `maxFreq()` to find the frequency of the modal value (i.e. how many time it occurs). Save your result to an object called `modal_freq`.


## Minihack 2: Outliers

1. Make sure you have the `world_happiness` data frame loaded into your environment. The following chunk of code creates a data frame with the `Corruption` variable and a scaled version of this variable called `Corruption_scaled`.

Run the following code:

```{r}
#install.packages("tidyverse") # if tidyverse is not already installed
library(tidyverse)

corruption_std <- world_happiness %>% 
  select(Country, Corruption) %>% 
  drop_na() %>% 
  mutate(Corruption_scaled = as.numeric(scale(Corruption))) %>% 
  arrange(desc(Corruption_scaled))
```

2. Create a histogram of `corruption_std$Corruption`. What do you notice about the shape of this distribution? How would you describe the skewness?

```{r}
hist(corruption_std$Corruption)
```

3. View `corruption_std`. Based on the z-scores (i.e. `Corruption_scaled`), which countries would be considered outliers on the `Corruption` variable?

4. After identifying which countries are outliers, use what you learned in last week's lab about [indexing dataframes](https://uopsych.github.io/psy611/labs/lab-1.html#data_frames){target="_blank"} to remove these rows from the data frame. 

-Hint #1: you can use the minus sign (`-`) for de-selecting.
<br /> 
-Hint #2: pay attention to rows `124` and `125`

```{r}
corruption_std_rm_outlier <- corruption_std[-c(124,125),]
```


## Minihack 3: Descriptive plots 

For this minihack, we're going to work with a slightly different version of the `world_happiness` data. You can [download the new verion here](https://drive.google.com/uc?export=download&id=1U1smVA5X839bJN9eHNR-ViuTYJ2Pw8h4). This version has two new variables:

-`War` represents whether or not a country was an active participant in WWII or was invested in by the US or Soviet Union just after WWII

-`Service` represents the proportion of the population that works in the service industry. ***Note: this variable has been simulated and is completely made up!***  

1. Import the new version of the data and save it to an object called `world_happiness_sim`.

```{r}
world_happiness_sim <- import("~/Downloads/world_happiness_2015_sim.csv")
```

2. Create a histogram of the `Service` variable. Set the number of bins to `30`. What do you notice about the shape of this distribution?

```{r}
hist(world_happiness_sim$Service, breaks = 30, xlab = "Service", main = "Distribution of service scores")
```

3. Look up the help documentation for `psych::describeBy()`. Use this function to get descriptive statistics for the `Service` variable for countries involved/not involved in WWII. (That is use `War` as your grouping variable). What are the means and standard deviations for the two groups? 

```{r}
describeBy(world_happiness_sim$Service, world_happiness_sim$War)
```

4. Based on what you observe about these group means, how might this explain the shape of the distribution of the `Service` variable?

## Minihack 4: Correlations

For this minihack, we're going to use the `cor()` function from `{psych}` to create a correlation matrix of the entire `world_happiness` dataset

1. First use the following snippet of code to create a version of the dataset that only contains numeric variables (i.e. gets rid of `Country`, as this is a categorical variable.) Don't worry about how this code works for now -- we'll get to that in a later class.

```{r eval=FALSE}
world_happiness_num <- world_happiness %>% 
  select_if(is.numeric)
```

2. Use `cor()` to generate a correlation matrix for all the variables in `world_happiness_num`. Use listwise deletion by specifying `use = "complete.obs"`. 

```{r}
cor(world_happiness_num, use = "complete.obs")
```


3. Now generate another correlation matrix, but this time use pairwise deletion by specifying `use = "pairwise.complete.obs"`.

```{r}
cor(world_happiness_num, use = "pairwise.complete.obs")
```

4. Compare your two correlation matrices. Whey do they have different numbers? What is the difference between pairwise and listwise deletion?
