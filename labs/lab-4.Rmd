---
title: "Lab 4: Probability Distributions"
output: 
  html_document: 
    theme: cosmo
    toc: yes
    toc_depth: 3
    toc_float: TRUE
---

```{r setup, include = FALSE}
# suppress scientific notation
options(scipen = 999)

# load packages
library(tidyverse)
library(magrittr)
library(psych)
library(gganimate)
library(panoply)
```

# Purpose

The purpose of today's lab is to introduce tools for sampling from and calculating statistics for different types of distributions. The content of the lab will be largely split into two sections. The first section will focus on binomial distributions. The second section will focus on normal distributions. At the end, we will briefly discuss tools for other types of distributions. As always, there are [Minihacks](#minihacks) at the end of this document to test your knowledge.

Today's lab will cover:

1. [Binomial Distributions](#binomial)
1. [Normal Distributions](#normal)

***

# Binomial {#binomial}

Imagine you are flipping a coin. If it is a fair coin, you would expect a 50% chance of the coin landing on heads and a 50% chance of the coin landing on heads. However, as shown in the animation below, every heads is not always paired with a tails. Sometimes there is a run of heads and sometimes there is a run of tails. Still, we would probably expect that, overall, there would be the same number of heads as tails. In other words, we would expect that if we flipped a single coin 100 times, the most likely outcome would be 50 heads and 50 tails.

```{r, echo = FALSE}
# set seed
set.seed(2)

# flip first coin
data_binom <- data.frame(event  = 1,
                         flip   = 1, 
                         result = rbinom(1, 1, 1/2))


# flip 99 other coins and repeat the data frame each time
for (i in 2:100) {
  data_binom <- rbind(data_binom,
                        data.frame(event  = rep(i, i),
                                   flip   = 1:i, 
                                   result = c(subset(data_binom, 
                                                     event == i - 1)$result,
                                              rbinom(1, 1, 1/2))))
}

# plot and animate the results of the flips 
data_binom %>%
  mutate(result = if_else(result == 1, "Heads", "Tails")) %>%
  ggplot(aes(x = result, fill = result)) +
    geom_bar(width = .5, alpha = .8) +
    scale_fill_manual(values = c("turquoise3",
                                 "darkorchid4")) +
    transition_reveal(event) +
    theme_bw(base_size = 15) +
    theme(legend.position = "none") +
    labs(title = "Outcome of 100 coin flips",
         y     = "Count",
         x     = "",
         caption = "Number of coin flips: {frame_along}")

```

As you might recall from class, our intuition about the outcome of the 100 coin flips can be described in terms of a binomial distribution. Essentially, the binomial distribution describes the theoretical probability of obtaining a certain outcome over a number of trials when (1) the outcome on every trial is binary (e.g., a coin landed on `heads` or a `tails`; a dice was either a `6` or it was not a `6`) and the probability of that outcome on every trial is the same (e.g., the probability of getting a `heads` on flip `1` is the same as the probability of getting a `heads` on flip `100`).

```{r, echo = FALSE}
# set seed
set.seed(2)

# create probability curve
data_binom <- data.frame(flip = seq(1, 100, 1),
                         prob = dbinom(seq(1, 100, 1), 100, 1/2))

# plot probability curve
ggplot(data_binom, aes(x = flip, y = prob)) +
  geom_line(size   = 1.5, 
            colour = "turquoise3",
            alpha  = .8) +
  labs(title = "Binomial Probability Distribution",
       x       = "Number of Heads in 100 Flips",
       y       = "Probability") +
  theme_bw(base_size = 15) 
```

If we plot the probabilty distribution of the example above, we can see that, as expected getting `50` `heads` is the most probable outcome, but that there are additional outcomes that are, although less probable, also possible. One could even expect to get `0` `heads` `r spround(dbinom(0, 100, 1/2) * 100, 29)`% of the time.

```{r, include = FALSE}
# set seed
set.seed(2)

# create data
data_binom <- data.frame(flips = seq(1, 1000, 1), 
                         prop  = map_dbl(seq(1, 1000, 1), 
                                         ~mean(rbinom(n    = .x, 
                                                      size = 1, 
                                                      prob = 1/2))))

# plot proportion of heads by number of flips
ggplot(data_binom, aes(x = flips, y = prop, colour = prop)) +
  geom_line(size = 1) +
  labs(x = "Number of Flips",
       y = "Proportion of Heads") +
  scale_colour_gradient2(low      = "turquoise3", 
                         mid      = "turquoise",
                         high     = "turquoise3", 
                         midpoint = 0.5) +
  scale_y_continuous(limits = c(0, 1)) +
  theme_bw(base_size = 15) +
  theme(legend.position = "none")

```

## rbinom

If we want to randomely sample trials from a binomial distribution, we can use the `rbinom()` function. The function takes three arguments. The first argument (`n`) is the number of trials to sample. If we wanted to flip `2` coins `10` times, we would write `n = 10`. The second argument (`size`) is the number of events associated with each trial. If we are flipping `2` coins, we would include `size = 2`. The third argument (`prob`) is the probability of success on a given trial. If we consider a `heads` a success and everything else a failure, we would include the argument `prob = 1/2`. Putting that altogether, we get `rbinom(n = 10, size = 2, .5)`.

```{r, include = FALSE}
set.seed(3)
```

```{r}
rbinom(n = 10, size = 2, prob = 1/2)
```

From the results, we can see we got `0` `heads` on the first toss of our two coins, `2` `heads` on the second toss our two coins, and `1` `head` on the third toss of our two coins.

*How would we change this if we were flipping `3` coins `10` times?*

```{r}
rbinom(n = 10, size = 3, prob = .5)
```

*What about rolling `5` `6`-sided die `10` times where getting a `6` is considered a sucessful outcome?*

```{r}
rbinom(n = 10, size = 5, prob = 1/6)
```

*What about pulling an `Ace` out of `1` deck of cards `100` times?*

```{r}
rbinom(n = 100, size = 1, prob = 1/13)
```

## dbinom

The function `dbinom` gives us the probability of getting any one result. It takes four arguments, but we will only concern ourselves with the first three: (1) `x` - the number of succesful outcomes, (2) `size` - the number of events, and (3) `prob` - the probability of success on a given event. 

To get the probability of getting `1` `head` by flipping `1` coin, we could run the following code.

```{r}
dbinom(x = 1, size = 1, prob = .50)
```

As you might expect, especially considering we set the probability at .50, there is a 50% probability of getting a head when you flip one coin.

**What about the probability of getting `1` head when you flip `2` coins?**

```{r}
# HT
.5 * .5

# TH
.5 * .5

dbinom(x = 1, size = 2, prob = .5)
```

**What about the probability of getting `1` head when you flip `3` coins?**
```{r}
# HTT
.5 * .5 * .5

# THT
.5 * .5 * .5

# TTH
.5 * .5 * .5

dbinom(x = 1, size = 3, prob = .5)
```

**What's the probability of drawing `2` Aces out of a deck of cards (with replacement)?**
```{r}
# AA
(1 / 13) * (1 / 13)

dbinom(x = 2, size = 2, prob = 1/13)
```

**What's the probability of drawing `0` Aces out of a deck of cards (with replacement)?**
```{r}
# 00
(12 / 13) * (12 / 13)

# method 1
dbinom(x = 0, size = 2, prob = 1/13)

# method 2
dbinom(x = 2, size = 2, prob = 12/13)
```

## pbinom

If we want to calculate the cumulative probability of getting a certain result, or the probability of getting a result equal to or less than what we expect, we would use the function `pbinom()`. This may not sound too important, but it is when you think about a p-value being the probability of getting a result equal to or more extreme than that observed in the sample. The function `pbinom()` takes essentially the same arguments as `dbinom()`, but instead of the first argument being called `x` it is called `q`.

Returning to the example from above, if wanted to get the probability of getting `1` or less `heads` when we flip `2` coins, we would use `pbinom(q = 1, size = 2, prob = 1/2)`.

```{r}
pbinom(q = 1, size = 2, prob = 1/2)
```

The result is `.75` because there is a `.50` probability of getting `1` head (`HT = .5 * .5; TH = .5 * .5`) and a `.25` chance of getting `0` heads (`TT = .5 * .5`).

*What's the probability of getting `1 or less` `heads` when flipping `10` coins?*

```{r}
pbinom(q = 1, size = 10, prob = 1/2)
```

*What's the probability of getting `1 or less` `6`s when  rolling `1` dice?*

```{r}
pbinom(q = 1, size = 1, prob = 1/6)
```

The function `pbinom()` can also take the argument `lower.tail` (defaults to `TRUE`). The argument `lower.tail` is what specifies what side of the probability distribution we should be testing from. In practical terms, it is what decided that we wanted `1 or less` heads rather than `greather than 1` heads.

For instance, if we wanted to test the probability of getting `greater than 1` heads when flipping two coins, we would simple specify `lower.tail = FALSE`.

```{r}
pbinom(q = 1, size = 2, prob = 1/2, lower.tail = FALSE)
```

*What's the probability of getting `greater than 3` `6`s when  rolling `9` dice?*

```{r}
pbinom(q = 3, size = 9, prob = 1/6, lower.tail = FALSE)
```

## qbinom

The function `qbinom()` essentially does the opposite of `pbinom`. What I mean by that is, instead of taking an outcome (`q`) and returning the probability of getting that outcome or less, it takes a probability (`p`) and returns the minimum outcome needed to achieve that probability.

For instance if you wanted the value for which there is `100`% probability of getting that value or less on `10` coin flips, you  would write `qbinom(p = 1.00, size = 10, prob = 1/2)`.

```{r}
qbinom(p = 1.00, size = 10, prob = 1/2)
```

Unsurprisingly, getting `10 or less` `heads` has a 100% chance of occurring when you flip 10 coins.

*With 100 coin flips, what is the number of heads (or less) has a .50 probability of occuring?*
```{r}
qbinom(p = .50, size = 100, prob = 1/2)
```

*With 100 coin flips, what is the number of heads (or less) has a .25 probability of occuring?*
```{r}
qbinom(p = .25, size = 100, prob = 1/2)
```

*With 100 coin flips, what is the number of heads (or greater) has a .25 probability of occuring?*
```{r}
qbinom(p = .25, size = 100, prob = 1/2, lower.tail = FALSE)
```

# Normal Distributions

Recall from class that a `normal distribution` is a continuous probability distribution that is defined by a mean ($\mu$) and a standard deviation ($\sigma$). Whereas the binomial distribution describes the theoretical probability of obtaining a certain outcome over a number of trials when the outcome of very trial is binarry, the normal distribution describe the theoretical probability of obtaining a certain outcome on a continuous distribution that has a certain mean ($\mu$) and standard deviation ($\sigma$)

## rnorm

In order to randomly sample observations from a normal distribution, we use the function `rnorm()`. Similar to `rbinom()`, `rnorm()` takes three arguments: (1) `n` - the number of observations to sample from the normal distribution, (2) `mean` - the mean of the normal distribution, and (3) `sd` - the standard deviation of the normal distribution. 

Below we sample `5` values from a normal distribution with a `mean` of `0` and a `sd` of `1`.

```{r, include = FALSE}
set.seed(2)
```

```{r}
rnorm(n = 5, mean = 0, sd = 1)
```

The five values were `-0.8969145`, `0.1848492`, `1.5878453`, `-1.13037567` and `-0.08025176`. Calculating the `mean()` and `sd()` of our `5` numbers is a bit of a sanity check. If we plot a histogram of the data, it doesn't look too normally distributed. 

```{r}
mean(c(-0.89691455, 0.18484918, 1.58784533, -1.13037567, -0.08025176))
sd(c(-0.89691455, 0.18484918, 1.58784533, -1.13037567, -0.08025176))
```

```{r, include = FALSE}
set.seed(2)
sample_size <- c(1, 5, 10, 15, 25, 50, 100, 250, 500, 750, 1000, 5000, 10000)

sim <- map_df(sample_size, function(sample_size) {
  set.seed(2)
  data_frame(sample_size = rep(sample_size, sample_size), 
             sample      = rnorm(sample_size, mean = 0, sd = 1))
  })
```

```{r}
sim %>%
  filter(sample_size == 5) %>%
  ggplot(aes(x = sample)) +
    geom_histogram(fill = "turquoise3", colour = "white", alpha = .7) +
    theme_bw(base_size = 16) +
    labs(x        = "x",
         y        = "Frequency",
         title    = "Sample Histogram") + 
    scale_x_continuous(limits = c(-4, 4)) 
```

Not to worry! As illustrated in the animation below, many samples do not appear normal until large enough samples are taken.
As shown in the animation below, when we draw observations

```{r}
plot3 <- ggplot(sim, aes(x = sample)) +
  geom_histogram(fill = "turquoise3", colour = "white", alpha = .7) +
  theme_bw(base_size = 16) +
  labs(x        = "x",
       y        = "Frequency",
       title    = "Sample Histogram",
       subtitle = "Sample Size: {closest_state}") + 
  scale_x_continuous(limits = c(-4, 4))  + 
  transition_states(sample_size, state_length = 2, wrap = FALSE) +
  view_follow(fixed_x = TRUE)

animate(plot3, nframes = 180, fps = 12)
```

**How would you sample 10 observations from a normal distribution with a mean of 100, and a standard deviation of 10?**

```{r}
x <- rnorm(n = 100, mean = 50, sd = 15)

x
```

**Are these descriptives for this sample what we would expect?**
```{r}
mean(x)
sd(x)
```

## dnorm

The normal distribution of `dbinom`


```{r, include = FALSE}
x <- seq(-4, 4, 0.001)
likelihood <- dnorm(x, 0, 1)
sim <- data.frame(x, likelihood)
ggplot(sim, aes(x, likelihood)) +
    stat_function(fun = dnorm, 
                xlim = c(-5,0),
                geom = "area",
                fill = "turquoise3") +
  geom_line(size = 1.2) +
  theme_bw()
```

```{r, include = FALSE}
dnorm_plot <- function(value) {
  ggplot(sim, aes(x, likelihood)) +
  geom_line(size = 1.2) +
  geom_segment(x = -4, 
               xend = value, 
               y = dnorm(value, mean = 0, sd = 1),
               yend = dnorm(value, mean = 0, sd = 1), 
               color = "turquoise3", 
               linetype = 2, 
               size = 1.4) +
  geom_segment(x = value, 
               xend = value, 
               y = 0,
               yend = dnorm(value, mean = 0, sd = 1), 
               color = "turquoise3", 
               linetype = 2, 
               size = 1.4) +
  annotate(geom = "label", x = value + .8, y = dnorm(value, mean = 0, sd = 1), label = round(dnorm(value, mean = 0, sd = 1), 3), colour = "turquoise3", size = 5) +
  geom_point(aes(x = value, y = dnorm(value, mean = 0, sd = 1)), size = 5, colour = "turquoise3") +
  scale_x_continuous(limits = c(-4, 4)) +
  theme_bw(base_size = 16)
}
```

Probability of a zero

```{r}
dnorm_plot(0)
```

```{r}
dnorm(0, mean = 0, sd = 1)
```

Probability of a 1

```{r}
dnorm_plot(1)
```

```{r}
dnorm(1, mean = 0, sd = 1)
```


Probability of -2

```{r}
dnorm_plot(-2)
```

```{r}
dnorm(-2, mean = 0, sd = 1)
```

***


## pnorm


```{r}
ball_plot <- function(q, lower.tail = TRUE){
  if (lower.tail == TRUE) {
  discretized <- data.frame(x = qnorm(ppoints(100), 0, 1)) %>% 
  mutate(include = ifelse(x <= q, "no", "yes"))
  } else {
  discretized <- data.frame(x = qnorm(ppoints(100), 0, 1)) %>% 
  mutate(include = ifelse(x >= q, "no", "yes"))
  }

ggplot(discretized, aes(x)) +
  geom_dotplot(aes(fill = include), binwidth = 0.29, alpha = .7, colour = "white") +
  geom_vline(xintercept = q, color = "firebrick", linetype = 2, size = 1.4) +
  scale_fill_manual(
    values = c("turquoise3", "gray40"),
    guide = "none") +
  theme_bw() +
  scale_y_continuous(name = "", 
                     breaks = NULL)
}
```

```{r}
ball_plot(0)
```

What's the probabiltiy of getting 0 or less when the mean is 0 and the sd = 1
```{r}
pnorm(0, mean = 0, sd = 1)
```

What's the probabiltiy of getting 1 or less when the mean is 0 and the sd = 1 (50 + half of 68)

```{r}
ball_plot(1)
```

```{r}
pnorm(1, mean = 0, sd = 1)
```

What's the probabiltiy of getting -1 or less when the mean is 0 and the sd = 1 (100 - 68 /2 )
```{r}
ball_plot(-1)
```

```{r}
pnorm(-1, mean = 0, sd = 1)
```

What's the probabiltiy of getting 2 or greater when the mean is 0 and the sd = 1 
```{r}
ball_plot(2, lower.tail = FALSE)
```

```{r}
pnorm(2, mean = 0, sd = 1, lower.tail = FALSE)
```


## qnorm 

for probability .50
```{r}
ball_plot(0)
```

```{r}
qnorm(0.5, 0, 1)
pnorm(0.2533471, 0, 1)
```

for probability .975
```{r}
ball_plot(qnorm(0.975, 0, 1))
```

```{r}
qnorm(0.975, 0, 1)
```

for probability .97 upper
```{r}
ball_plot(qnorm(0.975, 0, 1), lower.tail = FALSE)
```

```{r}
qnorm(0.975, 0, 1, lower.tail = FALSE)
```




# Minihacks {#minihacks}

You are welcome to work with a partner or in a small group of 2-3 people. If you have any questions, I would be happy to answer them!

## Minihack 1: Binomial Distributions

1. You are playing Dungeons and Dragons and your Dungeon master instutued

## Minihack 2: Normal Distributions

## Minihack 3: Other Distributions

1. My collaborater wants me to calculate a p-value for her, but I've sworn off null hypothesis testing. Fortunately, I was in the middle of writing this lab when I received her email. Use the `pchisq()` function to calculate the p-value for her Chi-Square test. She told me the following information about the test:
the chi-square value (`q`) was `1.00` 
there were `10` degrees of freedom (`df`)

```{r}
pchisq(3, 10, lower.tail = FALSE)
```


1. My collaborator just emailed me back and told me that she wasn't trying to calculate a p-value for a chi-square-test. She was trying to calculate a p-value for a t-test. I told her that I don't know any functions for t-tests, but she told me to Google it. Google (or take an educated guess) at how to calculate a p-value for my collaborator

```{r}
pt(3, 10, lower.tail = FALSE)
```

1. My collaborator also likes to mess with me and sometimes switches around letters in my code. The following code is calculating the cumulative probability of getting a value of `5` from a uniform distribution, but I want it to get the specific probability of getting a value of `5` from a uniform distribution. 

```{r}
dunif(x = 5, min = 0, max = 10)
```


