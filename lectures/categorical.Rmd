---
title: 'Categorical data analysis'
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [default, rladies, rladies-fonts, "my-theme.css"]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
--- 

```{r, echo = F, results = 'hide', message = F, warning = F}
library(here)
library(tidyverse)
library(psych)
library(knitr)
```


## Today...

* Overview
* Observed versus expected outcomes
* The chi-square goodness-of-fit test
* The chi-square independence test

---

### Key questions:

* How do we know if category frequencies are consistent with null hypothesis expectations?

* How do we know if category frequencies in a two-way table are related?

* What effect size should be used for two-way tables?

* How do we handle categories with very low frequencies?

* What if the data lack independence?

---

The sample data were obtained from Census at School, a website developed by the American Statistical Association to help students in the 4th through 12th grades understand statistical problem-solving. 

  * The site sponsors a survey that students can complete and a database that students and instructors can use to illustrate principles in quantitative methods.  
  * The database includes students from all 50 states, from grade levels 4 through 12, both boys and girls,  who have completed the survey dating back to 2010.  

---

We’ll focus on this one:

Which of the following superpowers would you most like to have? Select one.

* Invisibility
* Telepathy (read minds)
* Freeze time
* Super strength
* Fly

The responses from 247 randomly selected Oregon students were obtained from the Census at School database. 

---

```{r}
school = read_csv(here("data/census_at_school.csv"))
```

---

```{r frequency table, results = 'asis'}
school %>%
  group_by(Superpower) %>%
  summarize(Frequency = n()) %>%
  mutate(Proportion = Frequency/sum(Frequency)) %>%
  kable(., format = "html", digits = 2)
```

Descriptively this is interesting.  But, are the responses unusual or atypical in any way?  To answer that question, we need some basis for comparison—a null hypothesis.  One option would be to ask if the Oregon preferences are different compared to students from the general population.

---

class: center

```{r, echo = FALSE, message=FALSE, warning = F}
school_usa = read_csv(here("data/census_at_school_usa.csv"))

school %>%
  full_join(select(school_usa, Region, Superpower)) %>%
  mutate(Region = ifelse(Region == "OR", "OR", "USA")) %>%
  filter(!is.na(Superpower)) %>%
  group_by(Region, Superpower) %>%
  summarize(Frequency = n()) %>%
  mutate(Proportion = Frequency/sum(Frequency)) %>%
  ggplot(aes(x = Superpower, y = Proportion, fill = Region)) +
  geom_bar(stat = "identity", position = "dodge") +
  ggtitle("Category Proportion as a \nfunction of Source") +
  theme_bw(base_size = 20) + theme(legend.position = "bottom", axis.text.x = element_text(angle = 45, vjust = .5))
```

---

$H_0$: Oregon student superpower preferences are similar to the preferences of typical students in the United States.

$H_1$: Oregon student superpower preferences are different from the preferences of typical students in the United States. 

```{r, echo = F, results = 'asis', message=F}
school %>%
  full_join(select(school_usa, Region, Superpower)) %>%
  mutate(Region = ifelse(Region == "OR", "OR", "USA")) %>%
  filter(!is.na(Superpower)) %>%
  group_by(Region, Superpower) %>%
  summarize(Frequency = n()) %>%
  mutate(Proportion = Frequency/sum(Frequency)) %>%
  select(-Frequency) %>%
  spread(Region, Proportion) %>%
  kable(., col.names = c("Superpower", "OR Observed Proportion", "USA Proportion"), format = "html", digits = 2)
```

---

To compare the Oregon observed frequencies to the US data, we need to calculate the frequencies that would have been expected if Oregon was just like all of the other states.

The expected frequencies under this null model can be obtained by taking each preference category proportion from the US data (the null expectation) and multiplying it by the sample size for Oregon:

$$E_i = P_iN_{OR}$$
---
```{r, echo = F}
usa_freq = table(school_usa$Superpower)
usa_prop = usa_freq/sum(usa_freq)

school %>%
  filter(!is.na(Superpower)) %>%
  group_by(Superpower) %>%
  summarize(Frequency = n()) %>%
  mutate(Expected = usa_prop*247) %>%
  kable(., format = "html", digits = 2, col.names = c("Superpower", "Observed\nFreq", "Expected Freq"))
```

Now what?  We need some way to index differences between these frequencies, preferably one that translates easily into a sampling distribution so that we can sensibly determine how rare or unusual the Oregon data are compared to the US (null) distribution.

---

$$\chi^2_{df = k-1} = \sum^k_{i=1}\frac{(O_i-E_i)^2}{E_i}$$

The chi-square goodness of fit (GOF) statistic compares observed and expected frequencies.  It is small when the observed frequencies closely match the expected frequencies under the null hypothesis.  The chi-square distribution can be used to determine the particular $\chi^2$ value that corresponds to a rare or unusual profile of observed frequencies.

---

```{r create obs, echo = 3:4}
or_observed = table(school$Superpower)
or_expected = (table(school_usa$Superpower)/sum(table(school_usa$Superpower)))*247
or_observed
or_expected
```

---

```{r, ref.label="create obs", echo=3:4}

```

```{r}
(chi_square = sum((or_observed - or_expected)^2/or_expected))
```

---

```{r, ref.label="create obs", echo=3:4}

```

```{r, highlight=2}
(chi_square = sum((or_observed - or_expected)^2/or_expected))
(critical_val = qchisq(p = 0.95, df = length(or_expected)-1))
```

---

```{r, ref.label="create obs", echo=3:4}

```

```{r, highlight=2}
(chi_square = sum((or_observed - or_expected)^2/or_expected))
(critical_val = qchisq(p = 0.95, df = length(or_expected)-1))
(p_val = pchisq(q = chi_square, df = length(or_expected)-1, lower.tail = F))
```

---

.left-column[
.small[
The degrees of freedom are the number of categories (k) minus 1.  Given that the category frequencies must sum to the total sample size, k-1 category frequencies are free to vary; the last is determined.

]
]

```{r, echo = FALSE}
data.frame(x = seq(0,20)) %>%
  ggplot(aes(x = x)) +
  stat_function(fun = function(x) dchisq(x, df = length(or_expected)-1), geom = "line") +
  stat_function(fun = function(x) dchisq(x, df = length(or_expected)-1), geom = "area", fill = "purple", 
                xlim =c(critical_val, 20)) +
  geom_vline(aes(xintercept = critical_val), linetype = 2, color = "purple")+
    geom_vline(aes(xintercept = chi_square), linetype = 2, color = "black")+
  geom_text(aes(x = critical_val+2, y = dchisq(critical_val, length(or_expected)-1) + .05, 
                label = paste("Critical Value =", round (critical_val,2))), angle = 90)+
    geom_text(aes(x = chi_square+2, y = dchisq(critical_val, length(or_expected)-1) + .05, 
                label = paste("Critical Value =", round (chi_square,2))), angle = 90)+
  labs(x = "Chi-Square", y = "Density", title = "Area under the curve") +
  theme_light(base_size = 20)
```

---
.left-column[
.small[
The degrees of freedom are the number of categories (k) minus 1.  Given that the category frequencies must sum to the total sample size, k-1 category frequencies are free to vary; the last is determined.

]
]

```{r, echo = FALSE}
data.frame(x = seq(0,20)) %>%
  ggplot(aes(x = x)) +
  stat_function(fun = function(x) dchisq(x, df = length(or_expected)-1), geom = "line") +
  stat_function(fun = function(x) dchisq(x, df = length(or_expected)-1), geom = "area", fill = "purple", 
                xlim =c(chi_square, 20)) +
  geom_vline(aes(xintercept = critical_val), linetype = 2, color = "black")+
  geom_vline(aes(xintercept = chi_square), linetype = 2, color = "purple")+
  geom_text(aes(x = critical_val+2, y = dchisq(critical_val, length(or_expected)-1) + .05, 
                label = paste("Critical Value =", round (critical_val,2))), angle = 90)+
  geom_text(aes(x = chi_square+2, y = dchisq(critical_val, length(or_expected)-1) + .05, 
                label = paste("Critical Value =", round (chi_square,2))), angle = 90)+
  labs(x = "Chi-Square", y = "Density", title = "Area under the curve") +
  theme_light(base_size = 20)
```

